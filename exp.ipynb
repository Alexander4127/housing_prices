{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat features distributions\n",
      "|    | Name             | Vals                                         | Counts        |\n",
      "|---:|:-----------------|:---------------------------------------------|:--------------|\n",
      "|  0 | mainroad         | ['no' 'yes']                                 | [ 76 456]     |\n",
      "|  1 | guestroom        | ['no' 'yes']                                 | [437  95]     |\n",
      "|  2 | basement         | ['no' 'yes']                                 | [346 186]     |\n",
      "|  3 | hotwaterheating  | ['no' 'yes']                                 | [507  25]     |\n",
      "|  4 | airconditioning  | ['no' 'yes']                                 | [364 168]     |\n",
      "|  5 | prefarea         | ['no' 'yes']                                 | [406 126]     |\n",
      "|  6 | furnishingstatus | ['furnished' 'semi-furnished' 'unfurnished'] | [137 223 172] |\n",
      "\n",
      "Cat features converted to numerical (avoid overfitting on rare samples)\n",
      "|    | Name      | Vals          | Counts                    |\n",
      "|---:|:----------|:--------------|:--------------------------|\n",
      "|  0 | bathrooms | [1 2 3 4]     | [393 128  10   1]         |\n",
      "|  1 | bedrooms  | [1 2 3 4 5 6] | [  2 131 292  95  10   2] |\n",
      "|  2 | stories   | [1 2 3 4]     | [223 231  38  40]         |\n",
      "|  3 | parking   | [0 1 2 3]     | [292 121 107  12]         |\n",
      "\n",
      "DataFrame:\n",
      "|    |    price |   area |   bedrooms |   bathrooms |   stories | mainroad   | guestroom   | basement   | hotwaterheating   | airconditioning   |   parking | prefarea   | furnishingstatus   |\n",
      "|---:|---------:|-------:|-----------:|------------:|----------:|:-----------|:------------|:-----------|:------------------|:------------------|----------:|:-----------|:-------------------|\n",
      "|  0 | 13300000 |   7420 |          4 |           2 |         3 | yes        | no          | no         | no                | yes               |         2 | yes        | furnished          |\n",
      "|  1 | 12250000 |   8960 |          4 |           4 |         4 | yes        | no          | no         | no                | yes               |         3 | no         | furnished          |\n",
      "|  2 | 12250000 |   9960 |          3 |           2 |         2 | yes        | no          | yes        | no                | no                |         2 | yes        | semi-furnished     |\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "def print_stats(df, names, desc):\n",
    "    print(desc)\n",
    "    df_cat = pd.DataFrame(columns=[\"Name\", \"Vals\", \"Counts\"])\n",
    "    for ft in names:\n",
    "        df_cat.loc[len(df_cat)] = [ft] + list(np.unique(df[ft], return_counts=True))\n",
    "    print(df_cat.to_markdown(), end=\"\\n\\n\")\n",
    "\n",
    "# divide features to num and cat\n",
    "# here we move ordered cat features to numerical ones\n",
    "num_features = ['area', 'bathrooms', 'bedrooms', 'stories', 'parking']\n",
    "cat_features = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea', 'furnishingstatus']\n",
    "\n",
    "path = kagglehub.dataset_download(\"yasserh/housing-prices-dataset\")\n",
    "df = pd.read_csv(f\"{path}/Housing.csv\")\n",
    "\n",
    "assert len(num_features) + len(cat_features) + 1 == len(df.columns)\n",
    "\n",
    "# drop duplicates and \"similar\" objects\n",
    "df = df.drop_duplicates(subset=[\"area\", \"price\"])\n",
    "\n",
    "assert df.isna().sum().sum() == 0\n",
    "assert ((df[\"price\"] > 0) & (df.area > 0)).all()\n",
    "\n",
    "print_stats(df, cat_features, \"Cat features distributions\")\n",
    "\n",
    "print_stats(\n",
    "    df, num_features[1:],\n",
    "    \"Cat features converted to numerical (avoid overfitting on rare samples)\"\n",
    ")\n",
    "\n",
    "print(\"DataFrame:\")\n",
    "print(df.head(3).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find duplicates. Dropping them...\n",
      "Numerical features before removing extra values\n",
      "|    | Name      | Vals                                     | Counts                                                             |\n",
      "|---:|:----------|:-----------------------------------------|:-------------------------------------------------------------------|\n",
      "|  0 | bedrooms  | [ 0  1  2  3  4  5  6  7  8  9 10 11 33] | [  13  194 2737 9730 6849 1586  265   38   13    6    3    1    1] |\n",
      "|  1 | bathrooms | [0 1 2 3 4 5 6 7 8]                      | [   85  8254 10481  2217   335    48    12     2     2]            |\n",
      "|  2 | stories   | [1 2 3]                                  | [12447  8370   619]                                                |\n",
      "\n",
      "Final numerical features\n",
      "|    | Name      | Vals          | Counts                          |\n",
      "|---:|:----------|:--------------|:--------------------------------|\n",
      "|  0 | bedrooms  | [1 2 3 4 5 6] | [ 164 2709 9714 6828 1561  252] |\n",
      "|  1 | bathrooms | [1 2 3 4]     | [ 8248 10465  2197   318]       |\n",
      "|  2 | stories   | [1 2 3]       | [12338  8276   614]             |\n",
      "\n",
      "Additional DataFrame\n",
      "|    |   bedrooms |   bathrooms |   area |   stories |   price |\n",
      "|---:|-----------:|------------:|-------:|----------:|--------:|\n",
      "|  0 |          2 |           1 |   5650 |         1 |  231300 |\n",
      "|  1 |          3 |           2 |   7242 |         2 |  538000 |\n",
      "|  2 |          2 |           1 |  10000 |         1 |  180000 |\n"
     ]
    }
   ],
   "source": [
    "def load_add_data(main_df, main_num_features, main_cat_features):\n",
    "    path_add = kagglehub.dataset_download(\"sukhmandeepsinghbrar/housing-price-dataset\")\n",
    "\n",
    "    rename_columns = {\n",
    "        \"bedrooms\": \"bedrooms\",\n",
    "        \"bathrooms\": \"bathrooms\",\n",
    "        \"sqft_lot\": \"area\",\n",
    "        \"floors\": \"stories\",\n",
    "        \"price\": \"price\",\n",
    "    }\n",
    "\n",
    "    num_features = [\"area\", \"bedrooms\", \"bathrooms\", \"stories\"]\n",
    "    cat_features = []\n",
    "\n",
    "    assert sorted(num_features) == sorted(set(main_num_features) & set(rename_columns.values()))\n",
    "    assert sorted(cat_features) == sorted(set(main_cat_features) & set(rename_columns.values()))\n",
    "\n",
    "    df = pd.read_csv(f\"{path_add}/Housing.csv\")\n",
    "\n",
    "    # drop duplicates\n",
    "    if len(df['id'].unique()) != len(df):\n",
    "        print(f\"Find duplicates. Dropping them...\")\n",
    "        df = df.drop_duplicates(subset=[\"id\"])\n",
    "        assert len(df['id'].unique()) == len(df)\n",
    "\n",
    "    # keep only common columns with the initial dataframe\n",
    "    df = df[list(rename_columns.keys())].rename(columns=rename_columns).astype(int)\n",
    "\n",
    "    print_stats(df, num_features[1:], \"Numerical features before removing extra values\")\n",
    "\n",
    "    # remove cat features with extra values compared to orig df\n",
    "    for cat_feat in num_features[1:]:\n",
    "        orig_vals = main_df[cat_feat].unique()\n",
    "        df = df[df[cat_feat].isin(orig_vals)]\n",
    "\n",
    "    print_stats(df, num_features[1:], \"Final numerical features\")\n",
    "\n",
    "    # check nans and incorrect samples\n",
    "    assert df.isna().sum().sum() == 0\n",
    "    assert ((df[\"price\"] > 0) & (df.area > 0)).all()\n",
    "\n",
    "    return df, num_features, cat_features\n",
    "\n",
    "df_add, num_features_add, cat_features_add = load_add_data(df, num_features, cat_features)\n",
    "print(\"Additional DataFrame\")\n",
    "print(df_add.head(3).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def preprocess_data(df, num_features, cat_features):\n",
    "    enc_cat = OneHotEncoder().fit_transform(df[cat_features]).toarray()\n",
    "    return np.concatenate([df[num_features].to_numpy(), enc_cat], axis=1)\n",
    "\n",
    "def fill_features(df, df_pre, df_add, df_add_pre, column_names, is_cat=True):\n",
    "    df_add = df_add.copy()\n",
    "    for col_name in column_names:\n",
    "        if is_cat:\n",
    "            enc = OneHotEncoder().fit(df[[col_name]])\n",
    "            model = Ridge().fit(df_pre, enc.transform(df[[col_name]]).toarray())\n",
    "            df_add[col_name] = enc.inverse_transform(model.predict(df_add_pre)).reshape(-1)\n",
    "        else:\n",
    "            model = Ridge().fit(df_pre, df[col_name])\n",
    "            df_add[col_name] = np.clip(model.predict(df_add_pre).astype(int), a_min=df[col_name].min(), a_max=df[col_name].max())\n",
    "    return df_add\n",
    "\n",
    "df_pre = preprocess_data(df, [\"price\"] + num_features_add, cat_features_add)\n",
    "df_add_pre = preprocess_data(df_add, [\"price\"] + num_features_add, cat_features_add)\n",
    "\n",
    "df_add = fill_features(df, df_pre, df_add, df_add_pre, list(set(cat_features) - set(cat_features_add)))\n",
    "df_add = fill_features(df, df_pre, df_add, df_add_pre, list(set(num_features) - set(num_features_add)), is_cat=False)\n",
    "\n",
    "print(df_add.head(3).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synt(df, num_features, cat_features, num_samples):\n",
    "    df_gen = pd.DataFrame(columns=df.columns)\n",
    "    for ft in num_features:\n",
    "        df_gen[ft] = np.random.normal(\n",
    "            loc=df[ft].mean(), scale=df[ft].std(), size=num_samples\n",
    "        )\n",
    "    for ft in cat_features:\n",
    "        vals, counts = np.unique(df[ft], return_counts=True)\n",
    "        df_gen[ft] = [vals[idx] for idx in np.random.binomial(\n",
    "            n=len(vals), p=np.array(counts) / sum(counts), size=num_samples,\n",
    "        )]\n",
    "    return df_gen\n",
    "\n",
    "df_synt = generate_synt(df, num_features, cat_features, num_samples=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
